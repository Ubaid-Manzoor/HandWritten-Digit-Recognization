{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ubaid-Manzoor/HandWritten-Digit-Recognization/blob/master/Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "05H0dBDLI23D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Z-atjllvB_9b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.framework import ops\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mld-uAhx2OEG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist  = tf.keras.datasets.mnist\n",
        "\n",
        "(X_train , y_train) , (X_test , y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PTt2o76_22mT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = tf.one_hot(y_train , len(np.unique(y_train)))\n",
        "y_test = tf.one_hot(y_test , len(np.unique(y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4L0Ka_Mr8WMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b9ec6f4e-3a97-45f2-ee38-36eb71efc004"
      },
      "cell_type": "code",
      "source": [
        "#Flatten X\n",
        "X_train = X_train.reshape(X_train.shape[0] , -1).T\n",
        "X_test = X_test.reshape(X_test.shape[0] , -1).T\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 60000)\n",
            "(784, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aSVxDn805Mj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b3e58c23-2261-408d-c2e8-67d5cf5d6940"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  y_train = sess.run(y_train).T\n",
        "  y_test = sess.run(y_test).T\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 60000)\n",
            "(10, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Onz0xm3p6qDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "926e6c2e-2c35-4b5a-aaf4-617b64979a29"
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 60000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gPgdFUAKI32O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_placeholders(n_x , n_y):\n",
        "  \"\"\"\n",
        "  n_x -- num_px * num_px * 3(if RBG)\n",
        "  n_y -- number of classes in This case (10 classes)\n",
        "  \"\"\"\n",
        "  X = tf.placeholder(shape=[n_x,None] , dtype=tf.float32 , name=\"X\")\n",
        "  Y = tf.placeholder(shape=[n_y,None] , dtype=tf.float32 , name=\"Y\")\n",
        "  \n",
        "  return X,Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MmfEP_FYMEzR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_parameters_deep(layer_dims):\n",
        "  \"\"\"\n",
        "  layer_dims -- python list containing the dimension of each layer and is create manually as we are going to decide size of a layer \\\n",
        "                like [12222 , 20 , 7 , 4 , 1] 4layer model\n",
        "  \n",
        "  return:\n",
        "  parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
        "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
        "  \"\"\"\n",
        "  \n",
        "  np.random.seed(1)\n",
        "  parameters = {}\n",
        "  L = len(layer_dims) # number of layer in the network\n",
        "\n",
        "  for l in range(1 , L):\n",
        "    parameters['W' + str(l)] = tf.get_variable(\"W\" + str(l) , [layer_dims[l] , \n",
        "                                               layer_dims[l-1]] , initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    parameters['b' + str(l)] = tf.get_variable(\"b\" + str(l) , [layer_dims[l],1] , initializer=tf.zeros_initializer())\n",
        "    \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hSBDEAdS_Hk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def linear_forward(A , W , b):\n",
        "  Z = tf.add(tf.matmul(W,A),b)\n",
        "  \n",
        "  return Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TxGAttQaVd8T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def linear_activation_forward(A_prev , W , b):\n",
        "  Z = linear_forward(A_prev , W , b)\n",
        "  A = tf.nn.relu(Z)\n",
        "  \n",
        "  return A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K0S32dVjXSQb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def L_model_forward(X , parameters):\n",
        "\n",
        "  A = X\n",
        "  L = len(parameters) / 2\n",
        "  \n",
        "  for l in range(1,L):\n",
        "    A_prev = A\n",
        "    A = linear_activation_forward(A_prev, parameters['W'+str(l)], parameters['b' + str(l)])\n",
        "\n",
        "  ZL = linear_forward(A , parameters['W' + str(L)] , parameters['b' + str(L)])\n",
        "\n",
        "  return ZL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TYTCuz-1YGR_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_cost(Z3 , Y):\n",
        "  # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
        "  logits = tf.transpose(Z3)\n",
        "  labels = tf.transpose(Y)\n",
        "\n",
        "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
        "  \n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lQVNczdK01dz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[:, permutation]\n",
        "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
        "    \n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = int(math.floor(m/mini_batch_size)) # number of mini batches of size mini_batch_size in your partitionning\n",
        "\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eiNFehSvG90J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Define Dimension of all layers\n",
        "\n",
        "layer_dims = [784 , 50 , 50 , 25 ,10] # 5 layer model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pm1D2vZUYHkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train , Y_train , X_test , Y_test ,layer_dims ,learning_rate = 0.001 , num_epochs = 50 , \n",
        "          minibatch_size = 32 , print_cost = True):\n",
        "  \n",
        "  ops.reset_default_graph()\n",
        "  tf.set_random_seed(1)\n",
        "  #get n_x and n_y\n",
        "  (n_x , m) = X_train.shape\n",
        "  n_y = Y_train.shape[0]\n",
        "  \n",
        "  #create list to store the cost at each epochs\n",
        "  costs = []\n",
        "  #create placeholders\n",
        "  X ,Y = create_placeholders(n_x , n_y)\n",
        "  \n",
        "  #initialize all weights and biaes \n",
        "  parameters = initialize_parameters_deep(layer_dims)\n",
        "  \n",
        "  #Forward propogate to calculate Z of layer L\n",
        "  ZL = L_model_forward(X , parameters)\n",
        "  \n",
        "  #calculate Cost using ZL and Y\n",
        "  cost = compute_cost(ZL , Y)\n",
        "  \n",
        "  #Minimize the cost using Adam optimizer\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "  \n",
        "  # initialize all the global variable here (W and b are global varibles)\n",
        "  init = tf.global_variables_initializer()\n",
        "  \n",
        "  #Create a Session\n",
        "  with tf.Session() as sess:\n",
        "    #run init to initialize all variables\n",
        "    sess.run(init)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "      epoch_cost = 0\n",
        "      \n",
        "      minibatches = random_mini_batches(X_train , Y_train , minibatch_size)\n",
        "      \n",
        "      for minibatch in minibatches:\n",
        "        mini_X , mini_Y = minibatch\n",
        "\n",
        "        _ , mini_cost = sess.run([optimizer , cost] , feed_dict={X:mini_X , Y:mini_Y})\n",
        "        \n",
        "        epoch_cost += mini_cost\n",
        "      #if print_cost==True and (epoch % 10) == 0:\n",
        "      print(\"Cost after epoch %i: %f\" % (epoch , epoch_cost))\n",
        "     \n",
        "    parameters = sess.run(parameters)\n",
        "    \n",
        "    # Calculate the correct predictions\n",
        "    correct_prediction = tf.equal(tf.argmax(ZL), tf.argmax(Y))\n",
        "\n",
        "    # Calculate accuracy on the test set\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "    print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "    print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ReBolJMdhaRC",
        "colab_type": "code",
        "outputId": "0b5a02dd-fda8-45d7-ae67-8adc49e90cfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        }
      },
      "cell_type": "code",
      "source": [
        "parameters = model(X_train,y_train , X_test,y_test,layer_dims)"
      ],
      "execution_count": 404,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 2317.135460\n",
            "Cost after epoch 1: 584.782136\n",
            "Cost after epoch 2: 403.950671\n",
            "Cost after epoch 3: 328.984627\n",
            "Cost after epoch 4: 281.504755\n",
            "Cost after epoch 5: 240.939218\n",
            "Cost after epoch 6: 217.775042\n",
            "Cost after epoch 7: 193.882180\n",
            "Cost after epoch 8: 177.400659\n",
            "Cost after epoch 9: 169.902975\n",
            "Cost after epoch 10: 156.233744\n",
            "Cost after epoch 11: 144.910649\n",
            "Cost after epoch 12: 137.502055\n",
            "Cost after epoch 13: 133.151906\n",
            "Cost after epoch 14: 122.673725\n",
            "Cost after epoch 15: 118.968195\n",
            "Cost after epoch 16: 113.851469\n",
            "Cost after epoch 17: 112.576003\n",
            "Cost after epoch 18: 104.484537\n",
            "Cost after epoch 19: 110.292882\n",
            "Cost after epoch 20: 97.029733\n",
            "Cost after epoch 21: 95.963734\n",
            "Cost after epoch 22: 98.341732\n",
            "Cost after epoch 23: 94.987137\n",
            "Cost after epoch 24: 88.266214\n",
            "Cost after epoch 25: 86.953494\n",
            "Cost after epoch 26: 89.606938\n",
            "Cost after epoch 27: 87.701434\n",
            "Cost after epoch 28: 83.929165\n",
            "Cost after epoch 29: 77.702670\n",
            "Cost after epoch 30: 77.784909\n",
            "Cost after epoch 31: 81.066117\n",
            "Cost after epoch 32: 70.389694\n",
            "Cost after epoch 33: 78.582413\n",
            "Cost after epoch 34: 78.419286\n",
            "Cost after epoch 35: 76.973035\n",
            "Cost after epoch 36: 60.818796\n",
            "Cost after epoch 37: 78.144197\n",
            "Cost after epoch 38: 80.326787\n",
            "Cost after epoch 39: 66.756947\n",
            "Cost after epoch 40: 64.172272\n",
            "Cost after epoch 41: 68.434703\n",
            "Cost after epoch 42: 68.930422\n",
            "Cost after epoch 43: 67.263599\n",
            "Cost after epoch 44: 60.667479\n",
            "Cost after epoch 45: 69.992103\n",
            "Cost after epoch 46: 59.655948\n",
            "Cost after epoch 47: 70.993859\n",
            "Cost after epoch 48: 53.879361\n",
            "Cost after epoch 49: 69.510021\n",
            "('Train Accuracy:', 0.9856833)\n",
            "('Test Accuracy:', 0.9646)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uh4RLHR-HaC0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}